# Evaluating Frontier Models for Performance and Representation
Collaborators: Kennedy Martin, Ana Garcia, Helen Song, Jannatul Nayeem

TA: Preston Firestone  
Challenge Advisors: Sean Underwood, Mary Gibbs

- [About](#about)
- [Project Overview](#project-overview)
- [Included](#included)
- [Usage](#usage)
- [Execution](#execution)
- [License](#license)
- [Credit and Acknowledgments](#credit-and-acknowledgments)
- [References](#references)
  
# About 
Welcome to the Break Through Tech x Relativity 1B Bias Detection Project repository! This repository serves as the central hub for all code, documentation, and resources related to our project, which focuses on identifying and mitigating bias in machine learning models.

Our project is part of the Break Through Tech AI Program, where we work in collaboration with Relativity to tackle the issue of bias in AI models. We are developing tools and methodologies to analyze models, uncover inherent biases, and explore strategies to reduce or eliminate these biases. 

# Project Overview 

## Overview/Objective
**Investigate whether Large Language Models (LLMs) exhibit bias in regards to socioeconomic status.**

## Goals:

* Assess datasets
* Perturb and add onto existing datasets
* Obtain and compare model outputs
* Report on model evaluation


## Methodology

## Results and Key Findings

* Our results do not show any significant bias regarding socio economic standing. The use of different models, templates did not change this. However, we did find that models are more easily able to categorize negative sentiments as such whereas positive sentiments have a higher likelyhood to be catergorized as neutral. 

## Potential Next Steps
1. Model Comparisons
Use the framework to systematically compare and benchmark models for bias across key metrics.

3. Prompt Engineering
Test LLMs within the framework using prompt engineering for direct bias evaluation.

# Included 

* Major Project Deliverables
* Project Scope and Deliverables
* Team Progress Summary

## 2. Meeting Notes

* Meeting Notes August
* Meeting Notes September
* Meeting Notes October
* Meeting Notes November

# Usage 
- Whether you are contributing to the project, reviewing our findings, or interested in learning more about bias in AI, this repository provides all the necessary resources to follow our progress and understand our approach to bias detection and reduction in AI models.

# Execution 


# License 
* Apache License 2.0: An open-source license that is recommended for all AI Studio Challenge Projects.

# Credits And Acknowledgments {#sec-Credits And Acknowledgments}
* Preston Firestone (Teacher Assistant)
* Mary Gibbs (Challenge Advisor)
* Sean Underwood (Challenge Advisor)
* Kennedy Martin (Collaborator)
* Ana Garcia (Collaborator)
* Helen Song (Collaborator)
* Jannatul Nayeem (Collaborator)

# References 
- [Link to BBQ Github](https://github.com/nyu-mll/BBQ?tab=readme-ov-file)
- [Link to Amazon Fairness Github](https://github.com/amazon-science/generalized-fairness-metrics?tab=readme-ov-file)
- [Langtest Test Categories](https://langtest.org/docs/pages/docs/test_categories)
- [Hugging Face Model](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)
- 
